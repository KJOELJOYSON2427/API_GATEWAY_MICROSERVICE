{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nKZPXqvULYxea6S6AN6kT8Ev4aTm3bvm",
      "authorship_tag": "ABX9TyOIt/rFHAE4xesFWLBlVyai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KJOELJOYSON2427/API_GATEWAY_MICROSERVICE/blob/main/speech_recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Preprocess.run()\n",
        "    ‚Üì\n",
        "DatasetReader created\n",
        "    ‚Üì\n",
        "store_samples(\"train\")\n",
        "    ‚Üì\n",
        "store_samples(\"test\")\n",
        "So the high-level order is:\n",
        "\n",
        "Preprocess.run()\n",
        "\n",
        "store_samples(\"train\")\n",
        "\n",
        "store_samples(\"test\")\n",
        "\n",
        "Both train and test follow the exact same inner steps.\n",
        "</pre>"
      ],
      "metadata": {
        "id": "7es8GWCRiMkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import fnmatch\n",
        "import random\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lCFBO-wWmn4i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------------------------\n",
        "# POWER SPECTROGRAM CALCULATION\n",
        "# ------------------------------------------\n",
        "def calculatePowerSpectrogram(\n",
        "    audio_data,\n",
        "    samplerate,\n",
        "    n_mels=128,\n",
        "    n_fft=512,\n",
        "    hop_length=160):\n",
        "  spect = librosa.feature.melspectrogram(audio_data,sr=samplerate,n_mels=n_mels,n_fft=n_fft, hop_length=hop_length)\n",
        "  spectLog = librosa.power_to_db(spect, ref=np.max)\n",
        "  spectNorm = (spectLog - np.mean(spectLog)) / np.std(spectLog)\n",
        "  return spectNorm.T\n"
      ],
      "metadata": {
        "id": "YfMUFT0Wu2ZI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def letterToId(letter):\n",
        "    if letter == ' ':\n",
        "        return 27\n",
        "    if letter == \"'\":\n",
        "        return 26\n",
        "    return ord(letter) - ord('a')\n",
        "\n",
        "def sentenceToIds(sentence):\n",
        "  return [letterToId(letter) for letter in sentence.lower()]\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NUb73flYr88e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recursiveTraverse(directory, file_pattern):\n",
        "  for root, dirs, files in os.walk(directory):\n",
        "    for name in fnmatch.filter(files, file_pattern):\n",
        "      yield os.path.join(root, name)\n"
      ],
      "metadata": {
        "id": "blAV7l_HmSoo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetReader:\n",
        "  def __init__(self, data_directory):\n",
        "    self._data_directory = data_directory\n",
        "    self._transcript_dict_cache = None\n",
        "\n",
        "  @property\n",
        "  def _transcript_dict(self):\n",
        "    if self._transcript_dict_cache is None:\n",
        "      self._transcript_dict_cache = self._build_transcript()\n",
        "    return self._transcript_dict_cache\n",
        "\n",
        "  @staticmethod\n",
        "  def _get_transcript_entries(transcript_directory):\n",
        "    files = recursiveTraverse(transcript_directory, \"*.trans.txt\")\n",
        "    for tfile in files:\n",
        "        with open(tfile, 'r') as f:\n",
        "          for line in f:\n",
        "            line = line.rstrip('\\n')\n",
        "            audio_id, text = line.split(' ', 1)\n",
        "            yield audio_id, text\n",
        "  @staticmethod\n",
        "  def _extract_audio_id(audio_file):\n",
        "        return os.path.splitext(os.path.basename(audio_file))[0]\n",
        "\n",
        "  def _transform_sample(self, audio_file, preprocess_fnc):\n",
        "    audio, sr = librosa.load(audio_file, sr=None)\n",
        "    features = preprocess_fnc(audio, sr)\n",
        "    audio_id = self._extract_audio_id(audio_file)\n",
        "    return audio_id, features\n",
        "\n",
        "\n",
        "  def _build_transcript(self):\n",
        "       transcripts ={}\n",
        "       for audio_id, text in self._get_transcript_entries(self._data_directory):\n",
        "        transcripts[audio_id] = sentenceToIds(text)\n",
        "       return transcripts\n",
        "\n",
        "  def store_samples(self, directory, preprocess_fnc):\n",
        "    # Output path\n",
        "    out_dir = os.path.join(self._data_directory, \"preprocessed\", directory)\n",
        "    os.makedirs(out_dir, exists_ok=True)\n",
        "\n",
        "    #Input audio\n",
        "    audio_files = list(recursiveTraverse(\n",
        "            os.path.join(self._data_directory, directory), \"*.flac\"\n",
        "        ))\n",
        "    transcripts = self._transcript_dict\n",
        "\n",
        "    print(f\"Processing {len(audio_files)} audio files...\")\n",
        "\n",
        "    for audio_file in tqdm(audio_files):\n",
        "      audio_id = self._extract_audio_id(audio_file)\n",
        "\n",
        "      if audio_id not in transcripts:\n",
        "                continue\n",
        "\n",
        "      transcript = transcripts[audio_id]\n",
        "\n",
        "      audio_id, features = self._transform_sample(audio_file, preprocess_fnc)\n",
        "\n",
        "      np.savez(\n",
        "                os.path.join(out_dir, audio_id),\n",
        "                audio_fragments=features,\n",
        "                transcript=transcript\n",
        "            )\n",
        "    print(\"Done saving samples.\")\n"
      ],
      "metadata": {
        "id": "dpWneKRijqU2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ev7oeoTMBIZt"
      },
      "outputs": [],
      "source": [
        "class Preprocess:\n",
        "  def run(self, base_dir=\"/content/data\"):\n",
        "    reader = DatasetReader(base_dir)\n",
        "    preprocess_fnc = calculatePowerSpectrogram\n",
        "\n",
        "    reader.store_samples(\"train\", preprocess_fnc)\n",
        "    reader.store_samples(\"test\", preprocess_fnc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "J45QZcYt58wO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Raw Audio (.flac)\n",
        "    ‚Üì\n",
        "Preprocessing (mel / power spectrogram)\n",
        "    ‚Üì\n",
        "Saved .npz files\n",
        "    ‚Üì\n",
        "Data Generator (yields features + transcript)\n",
        "    ‚Üì\n",
        "‚úÖ InputBatchLoader / SingleInputLoader (THIS CODE)\n",
        "    ‚Üì\n",
        "Acoustic Model (CNN / LSTM / Transformer)\n",
        "    ‚Üì\n",
        "CTC Loss\n",
        "    ‚Üì\n",
        "Training / Decoding\n",
        "\n",
        "</pre>\n"
      ],
      "metadata": {
        "id": "Dvkyy2jtfDZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Before padding:\n",
        "\n",
        "Sample 1: [frame x 480]\n",
        "Sample 2: [frame x 620]\n",
        "\n",
        "After padding:\n",
        "\n",
        "Sample 1: [480 real | 140 zeros]\n",
        "Sample 2: [620 real]\n",
        "\n",
        "</pre>\n"
      ],
      "metadata": {
        "id": "jqOieXV1rBMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function converts variable-length frame sequences into a fixed-size batch tensor while remembering the real lengths."
      ],
      "metadata": {
        "id": "piIHH2bgrIZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1Ô∏è‚É£ COLAB + TF1 SETUP\n",
        "# ===============================\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "\n",
        "import threading\n",
        "import numpy as np\n",
        "from abc import abstractmethod\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "rmfvYTxOfB-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79ac69c-ea35-4c70-ec19-d75f713f115b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import abstractmethod\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ BASE INPUT LOADER\n",
        "# ===============================\n",
        "\n",
        "class BaseInputLoader:\n",
        "\n",
        "  def __init__(self, input_size):\n",
        "    self.input_size = input_size\n",
        "\n",
        "  def _get_inputs_feed_item(self, input_list):\n",
        "      \"\"\"\n",
        "        Pads variable-length inputs\n",
        "      \"\"\"\n",
        "      print(input_list.shape)\n",
        "      sequence_lengths = np.array(\n",
        "          [inp.shape[0] for inp in input_list]\n",
        "      )\n",
        "      max_time = sequence_lengths.max()\n",
        "      input_tensor = np.zeros(\n",
        "          (len(input_list), max_time, self.input_size)\n",
        "      )\n",
        "\n",
        "      for idx, inp in enumerate(input_list):\n",
        "        input_tensor[idx, :inp.shape[0], :] = inp\n",
        "      print(input_tensor.shape)\n",
        "      return input_tensor, sequence_lengths, max_time\n",
        "\n",
        "  @staticmethod\n",
        "  def _get_labels_feed_item(label_list, max_time):\n",
        "    \"\"\"\n",
        "        Converts labels to SparseTensorValue (needed for CTC)\n",
        "    \"\"\"\n",
        "    label_shape = np.array([len(label_list), max_time], dtype=np.int64)\n",
        "    label_indices = []\n",
        "    label_values = []\n",
        "    for label_idx, label in enumerate(label_list):\n",
        "      for time_idx, value in enumerate(label):\n",
        "          label_indices.append([label_idx, time_idx])\n",
        "          label_values.append(value)\n",
        "    label_indices = np.array(label_indices, dtype=np.int64)\n",
        "    label_values = np.array(label_values, dtype=np.int32)\n",
        "    return tf.SparseTensorValue(label_indices, label_values, label_shape)\n",
        "\n",
        "  @abstractmethod\n",
        "  def get_inputs(self):\n",
        "     raise NotImplementedError()"
      ],
      "metadata": {
        "id": "IOZRdAvtrNfJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 3Ô∏è‚É£ SINGLE INPUT LOADER (Inference)\n",
        "# ===============================\n",
        "class SingleInputLoader(BaseInputLoader):\n",
        "   def __init__(self, input_size):\n",
        "        super().__init__(input_size)\n",
        "        self.speech_input = None\n",
        "        batch_size = 1\n",
        "        with tf.device(\"/cpu:0\"):\n",
        "            self.inputs = tf.placeholder(\n",
        "                tf.float32, [batch_size, None, input_size], name=\"inputs\"\n",
        "            )\n",
        "            self.sequence_lengths = tf.placeholder(\n",
        "                tf.int32, [batch_size], name=\"sequence_lengths\"\n",
        "            )\n",
        "   def get_inputs(self):\n",
        "        return self.inputs, self.sequence_lengths, None\n",
        "\n",
        "   def set_input(self, speech_input):\n",
        "        self.speech_input = speech_input\n",
        "\n",
        "   def get_feed_dict(self):\n",
        "        if self.speech_input is None:\n",
        "            raise ValueError(\"Call set_input() first\")\n",
        "\n",
        "        input_tensor, seq_lengths, _ = self._get_inputs_feed_item(\n",
        "            [self.speech_input]\n",
        "        )\n",
        "        self.speech_input = None\n",
        "\n",
        "        return {\n",
        "            self.inputs: input_tensor,\n",
        "            self.sequence_lengths: seq_lengths\n",
        "        }\n"
      ],
      "metadata": {
        "id": "IE4Vr1vbydav"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 4Ô∏è‚É£ BATCH INPUT LOADER (Training)\n",
        "# ===============================\n",
        "class InputBatchLoader(BaseInputLoader):\n",
        "\n",
        "  def __init__(self, input_size, batch_size, data_generator_creator, max_steps=None):\n",
        "     super().__init__(input_size)\n",
        "\n",
        "     self.batch_size = batch_size\n",
        "     self.data_generator_creator = data_generator_creator\n",
        "     self.steps_left = max_steps\n",
        "\n",
        "     with tf.device(\"/cpu:0\"):\n",
        "      self.inputs = tf.placeholder(\n",
        "                tf.float32, [batch_size, None, input_size], name=\"inputs\"\n",
        "            )\n",
        "      self.sequence_lengths = tf.placeholder(\n",
        "                tf.int32, [batch_size], name=\"sequence_lengths\"\n",
        "            )\n",
        "      self.labels = tf.sparse_placeholder(tf.int32, name=\"labels\")\n",
        "\n",
        "      self.queue = tf.FIFOQueue(\n",
        "                capacity=50,\n",
        "                dtypes=[tf.float32, tf.int32, tf.string]\n",
        "      )\n",
        "\n",
        "      serialized_labels = tf.serialize_many_sparse(self.labels)\n",
        "\n",
        "      self.enqueue_op = self.queue.enqueue(\n",
        "                [self.inputs, self.sequence_lengths, serialized_labels]\n",
        "      )\n",
        "\n",
        "\n",
        "  def get_inputs(self):\n",
        "    inputs, seq_lengths, labels = self.queue.dequeue()\n",
        "    labels = tf.deserialize_many_sparse(labels, dtype=tf.int32)\n",
        "    return inputs, seq_lengths, labels\n",
        "\n",
        "\n",
        "  def _batch(self, iterable):\n",
        "      args = [iter(iterable)] * self.batch_size\n",
        "      return zip(*args)\n",
        "\n",
        "\n",
        "  def _enqueue(self, sess, coord):\n",
        "    generator = self.data_generator_creator()\n",
        "    for batch in self._batch(generator):\n",
        "        input_list, label_list = zip(*batch)\n",
        "        input_tensor, seq_lengths, max_time = \\\n",
        "                  self._get_inputs_feed_item(input_list)\n",
        "        labels = self._get_labels_feed_item(label_list, max_time)\n",
        "\n",
        "        sess.run(self.enqueue_op, feed_dict={\n",
        "            self.inputs: input_tensor,\n",
        "            self.sequence_lengths: seq_lengths,\n",
        "            self.labels: labels\n",
        "        })\n",
        "        if self.steps_left is not None:\n",
        "            self.steps_left -= 1\n",
        "            if self.steps_left == 0:\n",
        "                break\n",
        "\n",
        "        if coord.should_stop():\n",
        "          break\n",
        "\n",
        "    sess.run(self.queue.close())\n",
        "\n",
        "  def start_threads(self, sess, coord, n_threads=1):\n",
        "      threads = []\n",
        "      for _ in range(n_threads):\n",
        "          t = threading.Thread(target=self._enqueue, args=(sess, coord))\n",
        "          t.daemon = True\n",
        "          t.start()\n",
        "          coord.register_thread(t)\n",
        "          threads.append(t)\n",
        "      return threads"
      ],
      "metadata": {
        "id": "rwu4laDos_sn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def _batch( iterable):\n",
        "#         args = [iter(iterable)] * 2\n",
        "#         return zip(*args)\n",
        "\n",
        "\n",
        "def dummy_data_generator():\n",
        "    while True:\n",
        "        time_steps = np.random.randint(80, 150)\n",
        "        mel_features = np.random.rand(time_steps, 128).astype(np.float32)\n",
        "        transcript = np.random.randint(0, 28, size=np.random.randint(5, 15)).tolist()\n",
        "        yield mel_features, transcript\n",
        "\n",
        "# for batch in _batch(dummy_data_generator()):\n",
        "#     print(len(batch[0]))\n",
        "#     input_list, label_list = zip(*batch)\n",
        "# print(_batch(dummy_data_generator()))"
      ],
      "metadata": {
        "id": "DaNYxbbk0kT-",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 6Ô∏è‚É£ TEST TRAINING PIPELINE\n",
        "# ===============================\n",
        "# loader = InputBatchLoader(\n",
        "#     input_size=128,\n",
        "#     batch_size=2,\n",
        "#     data_generator_creator=dummy_data_generator,\n",
        "#     max_steps=3\n",
        "# )\n",
        "\n",
        "# inputs, seq_lengths, labels = loader.get_inputs()\n",
        "# with tf.Session() as sess:\n",
        "#     coord = tf.train.Coordinator()\n",
        "#     threads=loader.start_threads(sess, coord)\n",
        "#     for step in range(3):\n",
        "#         x, sl, lb = sess.run([inputs, seq_lengths, labels])\n",
        "#         print(f\"\\nStep {step + 1}\")\n",
        "#         print(\"Input shape:\", x.shape)\n",
        "#         print(\"Sequence lengths:\", sl)\n",
        "#         print(\"Sparse labels:\", lb)\n",
        "#     coord.request_stop()\n",
        "#     coord.join(threads)"
      ],
      "metadata": {
        "id": "PkMj5P3fzwvw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        " üß†**Core SpeechModel**\n",
        " CREATE INPUT LOADER\n",
        "        ‚Üì\n",
        "CREATE MODEL\n",
        "  ‚îú‚îÄ‚îÄ __init__()\n",
        "  ‚îÇ     ‚îú‚îÄ‚îÄ get_inputs()\n",
        "  ‚îÇ     ‚îî‚îÄ‚îÄ _create_network()\n",
        "  ‚îÇ            ‚îî‚îÄ‚îÄ _convolution() √ó many\n",
        "  ‚îÇ\n",
        "  ‚îú‚îÄ‚îÄ add_training_ops()\n",
        "  ‚îú‚îÄ‚îÄ add_decoding_ops()\n",
        "  ‚îú‚îÄ‚îÄ finalize()\n",
        "        ‚Üì\n",
        "CREATE SESSION\n",
        "        ‚Üì\n",
        "init_session()  ‚Üí variables initialized\n",
        "        ‚Üì\n",
        "TRAIN LOOP\n",
        "  ‚îî‚îÄ‚îÄ step(loss=True, update=True)\n",
        "        ‚Üì\n",
        "INFERENCE\n",
        "  ‚îî‚îÄ‚îÄ step(decode=True)\n",
        "\n",
        "</pre>"
      ],
      "metadata": {
        "id": "B11zr63njenG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "def xavier_initializer():\n",
        "    return GlorotUniform()"
      ],
      "metadata": {
        "id": "s6fqGO76tX3I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SpeechModel:\n",
        "\n",
        "  def __init__(self, input_loader: BaseInputLoader, input_size: int, num_classes: int):\n",
        "        self.input_loader = input_loader\n",
        "        self.input_size = input_size\n",
        "        self.convolution_count = 0\n",
        "        self.global_step = tf.Variable(0, trainable = False)\n",
        "\n",
        "        # üîπ Comes from InputLoader\n",
        "        self.inputs, self.sequence_lengths, self.labels = input_loader.get_inputs()\n",
        "\n",
        "         # üîπ Build network\n",
        "        self.logits = self._create_network(num_classes)\n",
        "\n",
        "        tf.summary.histogram('logits', self.logits)\n",
        "\n",
        "   # =========================\n",
        "    # TRAINING OPS\n",
        "    # =========================\n",
        "\n",
        "  def  add_training_ops(self, learning_rate=1e-3,\n",
        "                         learning_rate_decay_factor=0,\n",
        "                         max_gradient_norm=5.0,\n",
        "                         momentum=0.9):\n",
        "    self.learning_rate = tf.Variable(\n",
        "      float(learning_rate), trainable=False, dtype=tf.float32\n",
        "      )\n",
        "    if self.labels is not None:\n",
        "            with tf.name_scope('training'):\n",
        "                self.cost = tf.nn.ctc_loss(\n",
        "                    self.labels,\n",
        "                    self.logits,\n",
        "                    self.sequence_lengths // 2\n",
        "                )\n",
        "                self.avg_loss = tf.reduce_mean(self.cost)\n",
        "                optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "\n",
        "                gradients, variable = zip(\n",
        "                    *optimizer.compute_gradients(self.avg_loss)\n",
        "                )\n",
        "                clipped, _=tf.clip_by_global_norm(\n",
        "                    gradients, max_gradient_norm\n",
        "                )\n",
        "\n",
        "                self.update = optimizer.apply_gradients(\n",
        "                    zip(clipped, variable),\n",
        "                    global_step=self.global_step\n",
        "                )\n",
        "\n",
        "# =========================\n",
        "    # DECODING OPS\n",
        "    # =========================\n",
        "  def add_decoding_ops(self):\n",
        "\n",
        "        with tf.name_scope('decoding'):\n",
        "            self.decoded, self.log_probs = tf.nn.ctc_greedy_decoder(\n",
        "                self.logits,\n",
        "                self.sequence_lengths // 2,\n",
        "                merge_repeated=True\n",
        "            )\n",
        "# =========================\n",
        "\n",
        "    # SESSION INIT\n",
        "\n",
        "    # =========================\n",
        "\n",
        "  def init_session(self, sess, init_variables=True):\n",
        "\n",
        "        if init_variables:\n",
        "\n",
        "            sess.run(self.init)\n",
        "\n",
        "        self.summary_writer.add_graph(sess.graph)\n",
        "\n",
        "  # =========================\n",
        "    # FINALIZE\n",
        "    # =========================\n",
        "  def finalize(self, log_dir, run_name, run_type):\n",
        "    self.init = tf.global_variables_initializer()\n",
        "    self.saver = tf.train.Saver()\n",
        "    self.merged_summaries = tf.summary.merge_all()\n",
        "\n",
        "    self.summary_writer = tf.summary.FileWriter(\n",
        "    f\"{log_dir}/{run_name}_{run_type}\"\n",
        ")\n",
        "# =========================\n",
        "    # CONVOLUTION LAYER\n",
        "    # =========================\n",
        "\n",
        "  def _convultion(self, value, filter_width, stride,\n",
        "                  input_channels, out_channels,\n",
        "                     apply_non_linearity=True\n",
        "                  ):\n",
        "    layer_id = self.convolution_count\n",
        "    self.convolution_count += 1\n",
        "\n",
        "    with tf.variable_scope(f'conv_{layer_id}'):\n",
        "      filters = tf.get_variable(\n",
        "                'filters',\n",
        "                shape=[filter_width, input_channels, out_channels],\n",
        "                initializer=xavier_initializer()\n",
        "            )\n",
        "      bias = tf.get_variable(\n",
        "                'bias',\n",
        "                shape=[out_channels],\n",
        "                initializer=tf.zeros_initializer()\n",
        "            )\n",
        "\n",
        "      conv = tf.nn.conv1d(\n",
        "                value, filters, stride, padding='SAME'\n",
        "      )\n",
        "      conv=tf.nn.bias_add(conv, bias)\n",
        "      if apply_non_linearity:\n",
        "                return tf.nn.relu(conv), out_channels\n",
        "      else:\n",
        "          return conv, out_channels\n",
        "\n",
        "     # =========================\n",
        "    # TRAIN / DECODE STEP\n",
        "    # =========================\n",
        "  def step(self, sess, loss=True, update=True, decode=False):\n",
        "\n",
        "        fetches = []\n",
        "\n",
        "        if loss:\n",
        "            fetches.append(self.avg_loss)\n",
        "        if decode:\n",
        "            fetches.append(self.decoded)\n",
        "        if update:\n",
        "            fetches.append(self.update)\n",
        "\n",
        "        feed = self.input_loader.get_feed_dict() or {}\n",
        "\n",
        "        return sess.run(fetches, feed_dict=feed)\n",
        "  @abstractmethod\n",
        "  def _create_network(self, num_classes):\n",
        "        pass\n",
        "\n",
        "  def restore(self, session, checkpoint_directory: str, reset_learning_rate: float = None):\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_directory)\n",
        "\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "      self.saver.restore(session, ckpt.model_checkpoint_path)\n",
        "      self.init_session(session, init_variables=False)\n",
        "\n",
        "      if reset_learning_rate:\n",
        "        session.run(self.learning_rate.assign(reset_learning_rate))\n",
        "\n",
        "    else:\n",
        "      raise FileNotFoundError('No checkpoint for evaluation found')\n",
        "\n",
        "  def restore_or_create(self, session, checkpoint_directory: str, reset_learning_rate: float = None):\n",
        "    try:\n",
        "      self.restore(session, checkpoint_directory, reset_learning_rate)\n",
        "    except FileNotFoundError:\n",
        "      self.init_session(session, init_variables=True)\n"
      ],
      "metadata": {
        "id": "vM3jwatXt3ed"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Wav2LetterModel(SpeechModel):\n",
        "  def _create_network(self, num_classes):\n",
        "     # Input: [batch, time, 128]\n",
        "        outputs, channels = self._convolution(\n",
        "            self.inputs, 48, 2, self.input_size, 250\n",
        "        )\n",
        "\n",
        "        for _ in range(7):\n",
        "          outputs, channels = self._convolution(\n",
        "                outputs, 7, 1, channels, channels\n",
        "            )\n",
        "        outputs, channels = self._convolution(\n",
        "            outputs, 32, 1, channels, channels * 8\n",
        "        )\n",
        "\n",
        "        outputs, channels = self._convolution(\n",
        "            outputs, 1, 1, channels, channels\n",
        "        )\n",
        "\n",
        "        outputs, channels = self._convolution(\n",
        "            outputs, 1, 1, channels, num_classes, False\n",
        "        )\n",
        "\n",
        "        return tf.transpose(outputs, [1, 0, 2])\n",
        "\n"
      ],
      "metadata": {
        "id": "d1XCsbiBvGlM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_default_model(command, input_size, speech_input):\n",
        "    \"\"\"\n",
        "    command: 'train' or 'infer'\n",
        "    input_size: e.g. 128 (mel features)\n",
        "    speech_input: InputBatchLoader or SingleInputLoader\n",
        "    \"\"\"\n",
        "\n",
        "    # 1Ô∏è‚É£ Create model (this calls __init__ + _create_network)\n",
        "    model = Wav2LetterModel(\n",
        "        input_loader=speech_input,\n",
        "        input_size=input_size,\n",
        "        num_classes=29\n",
        "    )\n",
        "\n",
        "    # 2Ô∏è‚É£ Add ops based on mode\n",
        "    if command == 'train':\n",
        "        model.add_training_ops(\n",
        "            learning_rate=1e-3,\n",
        "            max_gradient_norm=5.0\n",
        "        )\n",
        "        model.add_decoding_ops()\n",
        "\n",
        "    else:  # inference / evaluation\n",
        "        model.add_training_ops()   # loss optional\n",
        "        model.add_decoding_ops()\n",
        "\n",
        "    # 3Ô∏è‚É£ Finalize graph\n",
        "    model.finalize(\n",
        "        log_dir='logs',\n",
        "        run_name='wav2letter',\n",
        "        run_type=command\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "q0v_V6yskKTn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TestExecutor"
      ],
      "metadata": {
        "id": "Mglosh9Ox6ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "from functools import partial\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "nwcSDLSAx75w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestExecutor(metaclass=ABCMeta):\n",
        "\n",
        "  def __init__(self, data_dir ='data'):\n",
        "    # 1Ô∏è‚É£ Dataset reader\n",
        "        self.reader = DatasetReader(data_dir)\n",
        "        # 2Ô∏è‚É£ Determine feature size (e.g., 128)\n",
        "        self.input_size = self.determine_input_size()\n",
        "\n",
        "        # 3Ô∏è‚É£ Create input loader\n",
        "        self.speech_input = InputBatchLoader(\n",
        "            input_size=self.input_size,\n",
        "            batch_size=64,\n",
        "            data_generator_creator=partial(\n",
        "                self.create_sample_generator,\n",
        "                self.get_loader_limit_count()\n",
        "            ),\n",
        "            max_steps=self.get_max_steps()\n",
        "        )\n",
        "\n",
        "\n",
        " # ------------------------------------\n",
        "    # INPUT SIZE\n",
        "  # ------------------------------------\n",
        "  def determine_input_size(self):\n",
        "        \"\"\"\n",
        "        Takes ONE sample and checks feature dimension\n",
        "        \"\"\"\n",
        "        sample, _ = next(self.create_sample_generator(limit_count=1))\n",
        "        return sample.shape[1]\n",
        "\n",
        "  @abstractmethod\n",
        "  def create_sample_generator(self, limit_count: int):\n",
        "        \"\"\"\n",
        "        Must yield: (audio_features, transcript)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "  def get_max_steps(self):\n",
        "        return None  # no step limit\n",
        "\n",
        "  # ------------------------------------\n",
        "    # PIPELINE START\n",
        "    # ------------------------------------\n",
        "  def start_pipeline(self, sess, n_threads=2):\n",
        "        coord = tf.train.Coordinator()\n",
        "        self.speech_input.start_threads(\n",
        "            sess=sess,\n",
        "            coord=coord,\n",
        "            n_threads=n_threads\n",
        "        )\n",
        "        return coord\n",
        "\n",
        "\n",
        " # ------------------------------------\n",
        "    # MODEL CREATION\n",
        "    # ------------------------------------\n",
        "  def create_model(self, sess, checkpoint_dir):\n",
        "        model = create_default_model(\n",
        "            command='evaluate',\n",
        "            input_size=self.input_size,\n",
        "            speech_input=self.speech_input\n",
        "        )\n",
        "  @abstractmethod\n",
        "  def get_loader_limit_count(self) -> int:\n",
        "        pass"
      ],
      "metadata": {
        "id": "Cf8fsPf4yBzh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "KxIqh2x3-SjU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train(TestExecutor):\n",
        "\n",
        "  def __init__(self, data_dir='data', limit=0):\n",
        "        self.limit = limit\n",
        "        super().__init__(data_dir)\n",
        "\n",
        "  # ----------------------------------\n",
        "  # DATA GENERATOR\n",
        "  # ----------------------------------\n",
        "  def create_sample_generator(self, limit_count: int):\n",
        "      return self.reader.load_samples(\n",
        "          directory='train',\n",
        "          loop_infinitely=True,\n",
        "          limit_count=limit_count,\n",
        "          feature_type='power'\n",
        "      )\n",
        "\n",
        "  def get_loader_limit_count(self) -> int:\n",
        "      return self.limit\n",
        "\n",
        "  # ----------------------------------\n",
        "  # MODEL\n",
        "  # ----------------------------------\n",
        "  def create_model(self, sess):\n",
        "      model = create_default_model(\n",
        "          command='train',\n",
        "          input_size=self.input_size,\n",
        "          speech_input=self.speech_input\n",
        "      )\n",
        "\n",
        "      model.restore_or_create(\n",
        "          session=sess,\n",
        "          checkpoint_directory='train/best-weights',\n",
        "          reset_learning_rate=1e-4\n",
        "      )\n",
        "      return model\n",
        "\n",
        "  def run(self):\n",
        "    tf.reset_default_graph()\n",
        "    with tf.Session() as sess:\n",
        "      model = self.create_model(sess)\n",
        "      coord = self.start_pipeline(sess, n_threads=2)\n",
        "\n",
        "      step_time = 0.0\n",
        "      loss_accum = 0.0\n",
        "      current_step = 0\n",
        "      print(\"üöÄ Begin training\")\n",
        "\n",
        "      try:\n",
        "          while not coord.should_stop():\n",
        "            current_step += 1\n",
        "            checkpoint_step = (current_step % 1000 == 0)\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # üî• THIS RUNS THE GRAPH\n",
        "            avg_loss, _ = model.step(\n",
        "                sess,\n",
        "                loss=True,\n",
        "                update=True,\n",
        "                decode=False\n",
        "            )\n",
        "\n",
        "            step_time += time.time() - start_time\n",
        "            loss_accum += avg_loss\n",
        "            if checkpoint_step:\n",
        "                global_step = sess.run(model.global_step)\n",
        "                learning_rate = sess.run(model.learning_rate)\n",
        "                perplexity = np.exp(avg_loss) if avg_loss < 300 else float(\"inf\")\n",
        "                print(\n",
        "                            f\"step {global_step} | \"\n",
        "                            f\"lr {learning_rate:.6f} | \"\n",
        "                            f\"loss {avg_loss:.2f} | \"\n",
        "                            f\"ppl {perplexity:.2f}\"\n",
        "                        )\n",
        "                # SAVE MODEL\n",
        "                os.makedirs('train/best-weights', exist_ok=True)\n",
        "                checkpoint_path = os.path.join(\n",
        "                    'train/best-weights', 'speech.ckpt'\n",
        "                )\n",
        "\n",
        "                model.saver.save(\n",
        "                            sess,\n",
        "                            checkpoint_path,\n",
        "                            global_step=model.global_step\n",
        "                        )\n",
        "\n",
        "                print(\"üíæ Weights saved\")\n",
        "\n",
        "                step_time = 0.0\n",
        "                loss_accum = 0.0\n",
        "      except tf.errors.OutOfRangeError:\n",
        "                print(\"‚úÖ Training finished\")\n",
        "      finally:\n",
        "                coord.request_stop()\n",
        "\n"
      ],
      "metadata": {
        "id": "5Iz1PJfS3-tm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Train(\n",
        "    data_dir='data',\n",
        "    limit=0   # 0 = use all samples\n",
        ")\n",
        "\n",
        "trainer.run()"
      ],
      "metadata": {
        "id": "E_jCHUxMASWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G-0LRjqckJ2v"
      }
    }
  ]
}